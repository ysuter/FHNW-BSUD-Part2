{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysuter/FHNW-BSUD-Part2/blob/main/L6-InformationExtraction/similarity_distance_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmmZp2PPahF1"
      },
      "source": [
        "# üßÆ Exploring Similarity and Distance Metrics in NLP and Data Science\n",
        "This notebook compares different similarity and distance metrics on **numeric**, **binary**, and **text** data.\n",
        "\n",
        "**Metrics included:**\n",
        "- Cosine similarity\n",
        "- Euclidean distance\n",
        "- Manhattan distance\n",
        "- Hamming distance\n",
        "- Pearson correlation\n",
        "\n",
        "**Goal:** Understand how metrics measure relationships and when to use them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIz1g4RVahF2"
      },
      "source": [
        "!pip install nltk scikit-learn seaborn matplotlib sentence-transformers -q\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances, pairwise_distances\n",
        "from scipy.spatial.distance import hamming, jaccard\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "print('‚úÖ Setup complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_evUPdZJahF3"
      },
      "source": [
        "# 1Ô∏è‚É£ Numeric Example ‚Äî Comparing Distance Metrics\n",
        "vectors = np.array([[1, 2, 3], [2, 3, 4], [10, 10, 10]])\n",
        "labels = ['Vector A', 'Vector B', 'Vector C']\n",
        "def show_heatmap(matrix, title, labels=labels):\n",
        "    sns.heatmap(matrix, annot=True, cmap='YlGnBu', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "cos_sim = cosine_similarity(vectors)\n",
        "show_heatmap(cos_sim, 'Cosine Similarity (Numeric)')\n",
        "eucl_dist = euclidean_distances(vectors)\n",
        "show_heatmap(eucl_dist, 'Euclidean Distance (Numeric)')\n",
        "man_dist = manhattan_distances(vectors)\n",
        "show_heatmap(man_dist, 'Manhattan Distance (Numeric)')\n",
        "pearson_corr = 1 - pairwise_distances(vectors, metric='correlation')\n",
        "show_heatmap(pearson_corr, 'Pearson Correlation (1 - Distance)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJNhiMt_ahF4"
      },
      "source": [
        "# 2Ô∏è‚É£ Binary Example ‚Äî Hamming and Jaccard Distances\n",
        "binary_vectors = np.array([[1,0,0,1,1],[1,1,0,1,0],[0,0,1,0,1]])\n",
        "labels_bin = ['Bin A', 'Bin B', 'Bin C']\n",
        "ham_dist = pairwise_distances(binary_vectors, metric='hamming')\n",
        "show_heatmap(ham_dist, 'Hamming Distance (Binary)', labels_bin)\n",
        "jacc_dist = pairwise_distances(binary_vectors, metric='jaccard')\n",
        "jacc_sim = 1 - jacc_dist\n",
        "show_heatmap(jacc_sim, 'Jaccard Similarity (Binary)', labels_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEJyXCYCahF4"
      },
      "source": [
        "# 3Ô∏è‚É£ Text Example ‚Äî Bag-of-Words & TF-IDF Similarity\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return ' '.join([t for t in tokens if t.isalpha() and t not in stop_words])\n",
        "texts = [\n",
        "    'AI improves medical diagnosis through image analysis.',\n",
        "    'Artificial intelligence helps doctors analyze radiology images.',\n",
        "    'The weather today is sunny and warm.'\n",
        "]\n",
        "clean_texts = [preprocess(t) for t in texts]\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform(clean_texts)\n",
        "cosine_bow = cosine_similarity(X_bow)\n",
        "show_heatmap(cosine_bow, 'Cosine Similarity (Bag-of-Words)', [f'Text {i+1}' for i in range(len(texts))])\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf = tfidf.fit_transform(clean_texts)\n",
        "cosine_tfidf = cosine_similarity(X_tfidf)\n",
        "show_heatmap(cosine_tfidf, 'Cosine Similarity (TF-IDF)', [f'Text {i+1}' for i in range(len(texts))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLHQi9q1ahF5"
      },
      "source": [
        "# 4Ô∏è‚É£ Semantic Embeddings ‚Äî Sentence Transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(texts)\n",
        "cosine_semantic = cosine_similarity(embeddings)\n",
        "show_heatmap(cosine_semantic, 'Cosine Similarity (Sentence Embeddings)', [f'Text {i+1}' for i in range(len(texts))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFkE1C4LahF5"
      },
      "source": [
        "## üß© Student Exercises\n",
        "1. Modify the inputs. How do distances change?\n",
        "2. Look into additional distance metrics and test them.\n",
        "3. Change one text to be unrelated. Which metric captures it best?\n",
        "4. Which metric is scale-sensitive?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}